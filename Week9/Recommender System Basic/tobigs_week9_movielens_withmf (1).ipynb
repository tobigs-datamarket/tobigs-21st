{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9주차 recsys basic 과제: Q1, Q2에있는 빈칸을 채워주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens data 탐방하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "#다양한 hyperparameter를 조절하기 위한 argparser\n",
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument('--latent_dim', type=int, default=10)\n",
    "argparser.add_argument('--batch_size', type=int, default=500)\n",
    "args = argparser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 이건 토치용입니다.\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MlDataLoader(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무비렌즈 데이터 불러주는  class: ml100k\n",
    "ML100k 클래스에서 data_path만 여러분이 u.data를 불러올 수 있는 경로로 바꿔주세요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# traintest split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from src.preprocess.mldataloader import MlDataLoader\n",
    "\n",
    "\n",
    "class ML100k():\n",
    "\n",
    "    def __init__(self,args) -> None:\n",
    "        self.args=args\n",
    "        self.call_data(args)\n",
    "        pass\n",
    "\n",
    "    def call_data(self, args) -> None:\n",
    "        self.args = args\n",
    "        data_path=\"u.data\" #이부분을 다운받은 데이터를 코랩에서 실행할 수 잇도록 바꿔주세요\n",
    "\n",
    "        self.data= pd.read_csv(data_path, sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "        self.num_users = self.data.user.nunique()\n",
    "        self.num_items = self.data.item.nunique()\n",
    "        self.num_ratings = len(self.data)    \n",
    "\n",
    "        # user, item index를 0부터 시작하도록 변경-. nn.Embedding에서 index가 0부터 시작하므로 1을 빼줍니다.\n",
    "        self.data.user = self.data.user -1\n",
    "        self.data.item = self.data.item -1\n",
    "        \n",
    "        \n",
    "        self.x = self.data[['user', 'item']].values\n",
    "        self.y= self.data.rating.values\n",
    "\n",
    "        # split data into train and test\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def get_dataframe(self):\n",
    "        # sort dataframe by user\n",
    "        return self.data[['user', 'item','rating']]\n",
    "    \n",
    "        \n",
    "    def load_torch_data(self):\n",
    "\n",
    "        # convert x to integer, y to floattenser\n",
    "        self.x_train = torch.tensor(self.x_train, dtype=torch.long)\n",
    "        self.y_train = torch.tensor(self.y_train, dtype=torch.float)\n",
    "        self.x_test = torch.tensor(self.x_test, dtype=torch.long)\n",
    "        self.y_test = torch.tensor(self.y_test, dtype=torch.float)\n",
    "        \n",
    "\n",
    "        train_dataset = MlDataLoader(self.x_train, self.y_train)\n",
    "        test_dataset = MlDataLoader(self.x_test, self.y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.args.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.args.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k=ML100k(args)\n",
    "dataframe=ml100k.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>879</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>715</td>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>275</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>11</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating\n",
       "0       195   241       3\n",
       "1       185   301       3\n",
       "2        21   376       1\n",
       "3       243    50       2\n",
       "4       165   345       1\n",
       "...     ...   ...     ...\n",
       "99995   879   475       3\n",
       "99996   715   203       5\n",
       "99997   275  1089       1\n",
       "99998    12   224       2\n",
       "99999    11   202       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe# 아래와 같이 user, item, rating으로 이루어진 데이터프레임이 나오게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Q1 : 해당 데이터 프레임을 통해서 각각의 유저가 item들의 점수를 어떻게 매겼는지를 나타내는 user-item matrix(rating matrix)를 만들어 주세요!!\n",
    "이 때 유저가 시청하지 않은 데이터는 -1로 처리해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., -1., -1., -1.],\n",
       "       [ 4., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 5., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1.,  5., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 코드를 작성해주세요\n",
    "rating_matrix = -1 * np.ones((dataframe['user'].nunique(), dataframe['item'].nunique()))\n",
    "\n",
    "for _, row in dataframe.iterrows():\n",
    "    rating_matrix[int(row['user']), int(row['item'])] = row['rating']\n",
    "\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1로 채워진 부분들을 채워주기 위해서 matrix factorization을 해봅시다\n",
    "이때 torch를 활용해서 sgd기반의 방법으로 user embedding과 item embedding을 훈련시켜 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 ml100k 클래스에서 torch dataloader를 불러오는 함수를 호출하여 데이터로더 형태의 train_loader, test_loader를 불러옵니다.\n",
    "train_loader, test_loader=ml100k.load_torch_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Matrix factorization model을 구현해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, args ,num_users,num_items) -> None:\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.user_embedding = nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, self.latent_dim)\n",
    "        #self.dropout = nn.Dropout(p=args.dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x) -> None:\n",
    "        # x: (batch_size, 2) : index 0:user, index 1:item\n",
    "        user = x[:, 0]\n",
    "        item = x[:, 1]\n",
    "        user = self.user_embedding(user)\n",
    "        #user shape: (batch_size, latent_dim) 우리가 원하는 유저가 표현된 latent_dim 차원의 벡터\n",
    "        item = self.item_embedding(item) \n",
    "        #item shape: (batch_size, latent_dim) 우리가 원하는 아이템이 표현된 latent_dim 차원의 벡터\n",
    "\n",
    "        out = torch.sum(user * item, dim=1) # 내적을 통해서 구하기,\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 EMbedding이 어떻게 동작하는지 확인한번만 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uemb_temp=nn.Embedding(ml100k.num_users, args.latent_dim)\n",
    "iembe_temp=nn.Embedding(ml100k.num_items, args.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([943, 10])\n",
      "torch.Size([1682, 10])\n"
     ]
    }
   ],
   "source": [
    "print(uemb_temp.weight.shape)\n",
    "print(iembe_temp.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3682, -1.1899,  0.0093,  ..., -0.4768,  0.5153, -1.8089],\n",
       "        [ 0.0606,  0.4581,  1.1962,  ...,  1.2150,  0.6276, -0.6744],\n",
       "        [ 0.8006,  0.3364, -1.3683,  ..., -0.6284, -1.6688, -0.9330],\n",
       "        ...,\n",
       "        [ 0.9663,  0.0650,  0.6307,  ..., -0.3677, -1.3728,  0.4366],\n",
       "        [-0.0569,  0.2808, -0.2574,  ..., -0.4656, -1.1558, -0.9891],\n",
       "        [-0.7415,  0.8622,  1.3843,  ..., -0.5496, -0.4085, -0.3296]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uemb_temp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1667, -0.9991,  0.0526,  ..., -0.9504, -0.3382,  0.6003],\n",
       "        [-0.0743,  1.1744,  0.6811,  ...,  0.3414, -0.7235,  0.6955],\n",
       "        [-0.7047, -1.3106, -0.0324,  ..., -0.7425, -0.1377, -0.0696],\n",
       "        ...,\n",
       "        [ 1.2958,  1.1490, -0.2905,  ...,  0.8301, -0.3480,  1.0937],\n",
       "        [-0.1542, -1.5898,  0.4081,  ..., -0.0673,  1.7011,  0.1263],\n",
       "        [ 1.7709,  0.6437,  0.4423,  ...,  1.1705,  0.4781,  0.2306]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iembe_temp.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 nn.Embedding을 통해서 유저, 아이템에 대한 embedding matrix를 저장하고 훈련시킬 수 잇는 네트워크라고 보시면 됩니다.(자연어에서 사용되는 nn.embedding과 같습니다.`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 이제 모델을 훈련시켜봅시다. 엄밀히 훈련시키려면 regularization,earlystopping등의 장치가 추가적으로 필요하지만, 돌아가는거만 확인하기 위해서 최대한 간단한 형태로 구현했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "    def train(self, data, test_data, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for (x,y) in data:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # print test loss\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for (x,y) in test_data:\n",
    "                    x = x.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    output = self.model(x)\n",
    "                    test_loss += self.criterion(output, y)\n",
    "\n",
    "                #normalize test loss\n",
    "            test_loss /= len(test_data)\n",
    "            print(f\"Epoch {epoch} train loss: {loss.item()} test loss: {test_loss.item()}\")\n",
    "\n",
    "        print(\"Training finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 2.3101413249969482 test loss: 2.0932018756866455\n",
      "Epoch 1 train loss: 1.2769538164138794 test loss: 1.3042798042297363\n",
      "Epoch 2 train loss: 1.0610748529434204 test loss: 1.2066370248794556\n",
      "Epoch 3 train loss: 1.0431791543960571 test loss: 1.2007395029067993\n",
      "Epoch 4 train loss: 0.8980586528778076 test loss: 1.2112562656402588\n",
      "Epoch 5 train loss: 0.9084991812705994 test loss: 1.2225910425186157\n",
      "Epoch 6 train loss: 0.8881762623786926 test loss: 1.255644679069519\n",
      "Epoch 7 train loss: 0.9196738600730896 test loss: 1.2566699981689453\n",
      "Epoch 8 train loss: 0.9592565298080444 test loss: 1.2458504438400269\n",
      "Epoch 9 train loss: 0.8061668872833252 test loss: 1.2583750486373901\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# model, optimizer, criterion, device를 정의합니다.\n",
    "model = MF(args, ml100k.num_users, ml100k.num_items)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# trainer를 정의합니다.\n",
    "trainer = Trainer(model, optimizer, criterion, device)\n",
    "trainer.train(train_loader, test_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아까 빈칸이었던 user-item matrix를 채워봅시다!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix=dataframe.pivot(index='user', columns='item', values='rating').fillna(-1) #pandas로 하면 너무느려져서 numpy로 바구고 진행합시다\n",
    "user_item_matrix=user_item_matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cpu() #모델을 cpu로 바꿔주고\n",
    "# 훈련된 embedding을 numpy로 바꿔줍니다.\n",
    "np_userembedding=model.user_embedding.weight.detach().numpy() \n",
    "np_itemembedding=model.item_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., -1., -1., -1.],\n",
       "       [ 4., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 5., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1.,  5., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. 아래 코드를 완성해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드를 완성해주세요\n",
    "for i in range(ml100k.num_users):\n",
    "    for j in range(ml100k.num_items):\n",
    "        if user_item_matrix[i, j] == -1:\n",
    "            # 사용자 i와 아이템 j 사이의 예상 평점 계산\n",
    "            user_embedding = model.user_embedding(torch.tensor([i]))\n",
    "            item_embedding = model.item_embedding(torch.tensor([j]))\n",
    "            predicted_rating = (user_embedding * item_embedding).sum().item()  # 내적 계산\n",
    "            user_item_matrix[i, j] = predicted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  3.        ,  4.        , ..., -3.38772869,\n",
       "         2.42809772, -3.60539389],\n",
       "       [ 4.        ,  2.50268245,  3.5964694 , ..., -2.05465388,\n",
       "         2.7081666 , -3.43079352],\n",
       "       [ 3.27203035,  1.38661289,  3.57996964, ..., -1.38879693,\n",
       "         5.10807562, -0.7986201 ],\n",
       "       ...,\n",
       "       [ 5.        ,  3.85034943,  3.85392714, ..., -5.01830864,\n",
       "         4.80982113, -4.76743317],\n",
       "       [ 4.51648617,  3.2486825 ,  3.56467795, ..., -3.96384883,\n",
       "         6.46917343, -2.37387514],\n",
       "       [ 2.80031133,  5.        ,  2.73359418, ..., -1.32345903,\n",
       "         0.5281117 , -5.83670568]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가로....\n",
    "결과를 보면 범위가 -3 에서  +5보다 큰 값도 나왔는데, 일반적으로는 0.5~5 사이로 normalization을 시켜주는 것 같습니다. 이건 생략하겠습니다 ㅎㅎ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
